{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OMZEiImFvbCy"
      },
      "source": [
        "# Sentiment Classification Using TinyBERT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Data with Hugging Face Datasets Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "REJST6u-PazK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/IMDB-Dataset.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['review', 'sentiment'],\n",
              "        num_rows: 35000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['review', 'sentiment'],\n",
              "        num_rows: 15000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = Dataset.from_pandas(data)\n",
        "dataset = dataset.train_test_split(test_size=0.3)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d6c2d4fe5064cebb679111c283d5a97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aab50923b28348afb33f6c6d91ce6644",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label2id = {'negative': 0, 'positive': 1}\n",
        "id2label = {0:'negative', 1:'positive'}\n",
        "\n",
        "dataset = dataset.map(lambda x: {'label': label2id[x['sentiment']]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'review': 'I gather at least a few people watched it on Sept.2 on TCM. If you did you know that Hedy had to change her name to avoid being associated with this movie when she came the U.S. It was a huge scandal and I gather that the original release in the U.S. was so chopped up by censors that it was practically unintelligible. I watched because I had just seen a documentary on \"bad women\", actresses in the U.S. pre- movie censorship board set up in the early \\'30s. It looked to me as though they got away with a lot more than Hedy\\'s most \"sensational\" shots in \"Ecstasy\". In fact Hedy looked positively innocent in this, by today\\'s standards, and it was nice to see her early unspoiled beauty. It was a nice, lyrical movie to relax to. I loved it for what it was: a simple romance. I watched it after pre- recording it during a sleepless early A.M. I would love to see the first version released in the U.S. for comparison\\'s sake.',\n",
              " 'sentiment': 'positive',\n",
              " 'label': 1}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model_ckpt = 'huawei-noah/TinyBERT_General_4L_312D'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a813371ae1524db5923da4e3e13fbc44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e514bdf6460a40cf9bfd38756ee80d45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer(dataset['train'][0]['review'])\n",
        "\n",
        "def tokenize(batch):\n",
        "    temp = tokenizer(batch['review'], padding=True, truncation=True, max_length=300)\n",
        "    return temp\n",
        "\n",
        "dataset = dataset.map(tokenize, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['review', 'sentiment', 'label', 'input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building Model Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install evaluate\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(label2id), label2id=label2id, id2label=id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir='train_dir',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['test'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38a319e76b424cc493fa261325384437",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3282 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4573, 'grad_norm': 7.713020324707031, 'learning_rate': 1.695307739183425e-05, 'epoch': 0.46}\n",
            "{'loss': 0.356, 'grad_norm': 7.362026691436768, 'learning_rate': 1.3906154783668494e-05, 'epoch': 0.91}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "445fb55e55e94a93a6921d7c8f52ee62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/469 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3203084170818329, 'eval_accuracy': 0.8662, 'eval_runtime': 27.8459, 'eval_samples_per_second': 538.679, 'eval_steps_per_second': 16.843, 'epoch': 1.0}\n",
            "{'loss': 0.3067, 'grad_norm': 10.578359603881836, 'learning_rate': 1.0859232175502743e-05, 'epoch': 1.37}\n",
            "{'loss': 0.3017, 'grad_norm': 9.168842315673828, 'learning_rate': 7.81230956733699e-06, 'epoch': 1.83}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab031c5cc9cc413eb5b8735d243b0a4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/469 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3019493818283081, 'eval_accuracy': 0.8788666666666667, 'eval_runtime': 27.8835, 'eval_samples_per_second': 537.952, 'eval_steps_per_second': 16.82, 'epoch': 2.0}\n",
            "{'loss': 0.2685, 'grad_norm': 12.404754638671875, 'learning_rate': 4.765386959171238e-06, 'epoch': 2.29}\n",
            "{'loss': 0.2632, 'grad_norm': 8.259003639221191, 'learning_rate': 1.7184643510054846e-06, 'epoch': 2.74}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce56db210dcd4210811859677303c2ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/469 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3005996644496918, 'eval_accuracy': 0.8802666666666666, 'eval_runtime': 27.9011, 'eval_samples_per_second': 537.613, 'eval_steps_per_second': 16.809, 'epoch': 3.0}\n",
            "{'train_runtime': 592.2551, 'train_samples_per_second': 177.288, 'train_steps_per_second': 5.542, 'train_loss': 0.319290198326692, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3282, training_loss=0.319290198326692, metrics={'train_runtime': 592.2551, 'train_samples_per_second': 177.288, 'train_steps_per_second': 5.542, 'total_flos': 882184338000000.0, 'train_loss': 0.319290198326692, 'epoch': 3.0})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "611988fa557d49c0b7316da0c4ca3e55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/469 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3005996644496918,\n",
              " 'eval_accuracy': 0.8802666666666666,\n",
              " 'eval_runtime': 28.0824,\n",
              " 'eval_samples_per_second': 534.142,\n",
              " 'eval_steps_per_second': 16.701,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Save and Load for Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model('tinybert-sentiment-analysis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = ['this movie was horrible, the plot was really boring. acting was okay',\n",
        "        'the movie is really sucked. there is not plot and acting was bad',\n",
        "        'what a beautiful movie. great plot. acting was good. will see it again']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.991597592830658},\n",
              " {'label': 'negative', 'score': 0.9916531443595886},\n",
              " {'label': 'positive', 'score': 0.9883714318275452}]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "classifier = pipeline('text-classification', model='tinybert-sentiment-analysis', device=device)\n",
        "\n",
        "classifier(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Push Model to AWS S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yhnjIqyT4adZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bucket already exists in your account!!! Feel free to use it.\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "bucket_name = 'mlops-kgptalkie'\n",
        "\n",
        "def create_bucket(bucket_name):\n",
        "    response = s3.list_buckets()\n",
        "    buckets = [buck['Name'] for buck in response['Buckets']]\n",
        "    if bucket_name not in buckets:\n",
        "        s3.create_bucket(Bucket=bucket_name)\n",
        "        print(\"Bucket is created\")\n",
        "\n",
        "    else:\n",
        "        print(\"Bucket already exists in your account!!! Feel free to use it.\")\n",
        "\n",
        "create_bucket(bucket_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# upload model folder to s3 bucket ml-models/tinybert-sentiment-analysis\n",
        "import os\n",
        "import boto3\n",
        "\n",
        "s3 = boto3.client('s3')\n",
        "bucket_name = 'mlops-kgptalkie'\n",
        "\n",
        "def upload_directory(directory_path, s3_prefix):\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file).replace(\"\\\\\", \"/\")\n",
        "            relpath = os.path.relpath(file_path, directory_path)\n",
        "            s3_key = os.path.join(s3_prefix, relpath).replace(\"\\\\\", \"/\")\n",
        "            \n",
        "            s3.upload_file(file_path, bucket_name, s3_key)\n",
        "\n",
        "\n",
        "upload_directory('tinybert-sentiment-analysis', 'ml-models/tinybert-sentiment-analysis')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# s3://mlops-kgptalkie/ml-models/tinybert-sentiment-analysis/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment_Classification_using_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
